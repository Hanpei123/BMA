{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Model Averaging (BMA) with Expectation-Maximization (EM) Algorithm\n",
    "\n",
    "The Bayesian Model Averaging (BMA) method is applied to combine forecasts from multiple models to produce a more robust and accurate forecast. The Expectation-Maximization (EM) algorithm is used to iteratively optimize the weights and variances of each model.\n",
    "\n",
    "## Function Overview\n",
    "\n",
    "```{python} \n",
    "def bma_em(y, forecasted_y, max_iterations=1000, tol=1e-8):\n",
    "```\n",
    "\n",
    "**Parameters**:\n",
    "- `y`: Observed values\n",
    "- `forecasted_y`: Forecasts from different models as a 2D array, where each column represents a different model.\n",
    "- `max_iterations`: Maximum number of iterations for the EM algorithm.\n",
    "- `tol`: Convergence tolerance to stop the algorithm once improvements become negligible.\n",
    "\n",
    "## Initialization\n",
    "\n",
    " ```{python} \n",
    "T, K = forecasted_y.shape\n",
    "w = np.full(K, 1/K)\n",
    "sigma = np.array([np.std(y - forecasted_y[:, k]) for k in range(K)])\n",
    "```\n",
    "\n",
    "- `T` is the number of observations, and `K` is the number of models.\n",
    "- `w` contains the initial weights for each model, uniformly distributed.\n",
    "- `sigma` contains the initial standard deviations for each model, computed as the standard deviation of the difference between the observed values and each model's forecast.\n",
    "\n",
    "## EM Algorithm Loop\n",
    "\n",
    "1. **E-step**: Computes the expectation of the latent variables based on current parameters.\n",
    "\n",
    "    For each observation and model, we calculate the responsibility (or weight) of that model for the current observation. The responsibility is proportional to the likelihood of the observation under the model's current parameters. These responsibilities are stored in the `z` matrix.\n",
    "\n",
    "2. **M-step**: Updates the parameters based on the responsibilities computed in the E-step.\n",
    "\n",
    "    Weights for each model are updated by taking the average of their responsibilities over all observations.\n",
    "    The variance (`sigma`) for each model is updated by considering the weighted variance of the model's forecast errors.\n",
    "\n",
    "3. **Log-likelihood computation**: The log-likelihood measures the likelihood of the observed data given the current parameters. It's used as a convergence criterion. The algorithm stops when the increase in log-likelihood is smaller than the tolerance `tol`.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "The function returns the optimized weights `w` and variances `sigma` for each model.\n",
    "\n",
    "---\n",
    "\n",
    "## Testing with Random Data\n",
    "\n",
    "After the function, random datasets are generated for testing. The dataset includes 100 observations (`y`) and forecasts from 3 models (`forecasted_y`). The function is then executed with this data, and the optimized weights and sigma values are printed.\n",
    "\n",
    "---\n",
    "\n",
    "## Validation and Visualization\n",
    "\n",
    "### Root Mean Square Error (RMSE)\n",
    "The RMSE gives a sense of the magnitude of the error between the forecasted values and observed values. It's commonly used because it punishes large errors more severely than smaller ones.\n",
    "\n",
    "### Skill Score\n",
    "The skill score is a measure of the relative improvement of one forecast over another. It can be used to compare the performance of the BMA forecast to individual model forecasts or a simple average of the model forecasts.\n",
    "\n",
    "### Continuous Rank Probability Score (CRPS)\n",
    "CRPS generalizes the RMSE to probabilistic forecasts. It provides a measure of the difference between the forecasted probabilities and the observed outcomes.\n",
    "\n",
    "### Attributes Diagram\n",
    "The attributes diagram is a graphical representation that allows one to assess the reliability, resolution, and sharpness of probabilistic forecasts.\n",
    "\n",
    "### Leave-Two-Out Cross-Validation\n",
    "Given the autocorrelation in the forecasts, a leave-two-out cross-validation is applied. This means that for each pair of observations left out, the model is trained on the remaining data and its performance is evaluated on the left-out pair. This approach provides a robust estimate of the model's performance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bma_em(y, forecasted_y, max_iterations=1000, tol=1e-8):\n",
    "    \"\"\"\n",
    "    Bayesian Model Averaging using EM Algorithm.\n",
    "    \n",
    "    Parameters:\n",
    "    - y: observed values\n",
    "    - forecasted_y: forecasted values from different models (2D array)\n",
    "    - max_iterations: Maximum number of iterations for the EM algorithm\n",
    "    - tol: Convergence tolerance\n",
    "    \n",
    "    Returns:\n",
    "    - w: Weights for each model\n",
    "    - sigma: Variance for each model's forecast\n",
    "    \"\"\"\n",
    "    T, K = forecasted_y.shape\n",
    "    w = np.full(K, 1/K)  # Initialize weights uniformly\n",
    "    sigma = np.array([np.std(y - forecasted_y[:, k]) for k in range(K)])  # Initialize variances\n",
    "    \n",
    "    prev_L = -np.inf\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # E-step\n",
    "        z = np.zeros((T, K))\n",
    "        for t in range(T):\n",
    "            total = sum([w[k] * (1 / (sigma[k] * np.sqrt(2 * np.pi))) * \n",
    "                         np.exp(-0.5 * ((y[t] - forecasted_y[t, k]) / sigma[k])**2) for k in range(K)])\n",
    "            for k in range(K):\n",
    "                z[t, k] = (w[k] * (1 / (sigma[k] * np.sqrt(2 * np.pi))) * \n",
    "                          np.exp(-0.5 * ((y[t] - forecasted_y[t, k]) / sigma[k])**2)) / total\n",
    "        \n",
    "        # M-step\n",
    "        w = z.mean(axis=0)\n",
    "        for k in range(K):\n",
    "            sigma[k] = np.sqrt(sum(z[:, k] * (y - forecasted_y[:, k])**2) / sum(z[:, k]))\n",
    "        \n",
    "        # Log-likelihood\n",
    "        L = sum([np.log(sum([w[k] * (1 / (sigma[k] * np.sqrt(2 * np.pi))) * \n",
    "                            np.exp(-0.5 * ((y[t] - forecasted_y[t, k]) / sigma[k])**2) for k in range(K)])) for t in range(T)])\n",
    "        \n",
    "        # Convergence check\n",
    "        if L - prev_L < tol:\n",
    "            break\n",
    "        prev_L = L\n",
    "    \n",
    "    return w, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [0.39385837 0.14429187 0.46184976]\n",
      "Sigma: [1.24849487 0.33603718 0.91692496]\n"
     ]
    }
   ],
   "source": [
    "# Generate random data\n",
    "np.random.seed(0)  # For reproducibility\n",
    "y = np.random.randn(100)\n",
    "forecasted_y = np.random.randn(100, 3)  # Sample forecasts from 3 models\n",
    "\n",
    "w, sigma = bma_em(y, forecasted_y)\n",
    "print(\"Weights:\", w)\n",
    "print(\"Sigma:\", sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.08963898479372\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.integrate import quad\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "def skill_score(y_true, y_pred):\n",
    "    mse_pred = mean_squared_error(y_true, y_pred)\n",
    "    climatology = np.mean(y_true)\n",
    "    mse_clim = mean_squared_error(y_true, [climatology]*len(y_true))\n",
    "    ss = 1 - mse_pred / mse_clim   \n",
    "    return ss\n",
    "\n",
    "\n",
    "def crps(y_true, y_pred, sigma):\n",
    "    norm = (y_true - y_pred) / sigma\n",
    "    first_term = y_true - y_pred\n",
    "    second_term = sigma * (2 * norm.cdf(norm) - 1)\n",
    "    third_term = 2 * norm.pdf(norm)\n",
    "    fourth_term = (norm ** 2)\n",
    "    return first_term * (second_term - third_term + fourth_term)\n",
    "\n",
    "def leave_two_out_cv(y, forecasted_y, func):\n",
    "    n = len(y)\n",
    "    results = []\n",
    "\n",
    "    for i in range(0, n, 2):\n",
    "        y_train = np.delete(y, [i, i+1])\n",
    "        forecasted_y_train = np.delete(forecasted_y, [i, i+1], axis=0)\n",
    "\n",
    "        y_test = y[i:i+2]\n",
    "        forecasted_y_test = forecasted_y[i:i+2]\n",
    "\n",
    "        w, sigma = func(y_train, forecasted_y_train)\n",
    "        y_pred = np.dot(w, forecasted_y_test.T)\n",
    "        \n",
    "        results.append((y_test, y_pred))\n",
    "    return results\n",
    "\n",
    "cv_results = leave_two_out_cv(y, forecasted_y, bma_em)\n",
    "rmses = [rmse(y_test, y_pred) for y_test, y_pred in cv_results]\n",
    "print(\"RMSE:\", np.mean(rmses))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
